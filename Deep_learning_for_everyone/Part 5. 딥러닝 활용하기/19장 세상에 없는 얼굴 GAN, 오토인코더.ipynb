{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3e79ef-d390-43ce-9d4f-85b641d80c19",
   "metadata": {},
   "source": [
    "#### 1. 가짜 제조 공장, 생성자 (생성자 모델 만들기)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371b7f40-23eb-4863-8040-c910d1cce1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Reshape, UpSampling2D, Conv2D, Activation\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a8802-7ad1-4de7-8757-fd713bec088e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2. 진위를 가려내는 장치, 판별자 (판별자 모델 만들기)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f83b91-e2dc-468a-baaf-975733548b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# 모델 이름 = discriminator\n",
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28, 28, 1), padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fedb079-4ce2-4a80-ad3f-4ff58cf6dca3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3. 적대적 신경망 실행하기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f40b854d-eeb0-44ff-a434-645134ca1bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_72\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_72\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">865,281</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_6 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │       \u001b[38;5;34m865,281\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_7 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m212,865\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,078,146</span> (4.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,078,146\u001b[0m (4.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">852,609</span> (3.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m852,609\u001b[0m (3.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,537</span> (881.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m225,537\u001b[0m (881.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529414a0-94c4-4d6d-8512-57aee3825de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # 가로 28픽셀, 세로 28픽셀, 흑백이므로 1로 설정\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "    # 0~255 사이 픽셀 값 중 127.5를 뺀 후 127.5로 나누면 -1~1 사이의 값이 됩니다\n",
    "    X_train = (X_train - 127.5) / 127.5\n",
    "\n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.ones((batch_size, 1))\n",
    "\n",
    "    for i in range(epoch):\n",
    "        # 실제 데이터를 판별자에 입력\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "        # 가상 이미지를 판별자에 입력\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "        # 판별자와 생성자의 오차 계산\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "        print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc43bf9-93b8-4d74-aaed-d928525116b4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "##### 실습 | GAN 모델 만들기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e39a3-7e23-4f0b-b794-16b423bf4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Reshape, UpSampling2D, Conv2D, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU, Conv2D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 생성자 모델\n",
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "\n",
    "# 판별자 모델\n",
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28, 28, 1), padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "\n",
    "# 생성자와 판별자 모델을 연결시키는 gan 모델\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 신경망 실행 함수\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # 가로 28픽셀, 세로 28픽셀, 흑백이므로 1로 설정\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "    # 0~255 사이 픽셀 값 중 127.5를 뺀 후 127.5로 나누면 -1~1 사이의 값이 됩니다\n",
    "    X_train = (X_train - 127.5) / 127.5\n",
    "\n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.ones((batch_size, 1))\n",
    "\n",
    "    for i in range(epoch):\n",
    "        # 실제 데이터를 판별자에 입력\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "        # 가상 이미지를 판별자에 입력\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "        # 판별자와 생성자의 오차 계산\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "        print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "        # 중간 과정을 이미지로 저장\n",
    "        # 정해진 인터벌만큼 학습되면 폴더에 이미지를 저장\n",
    "        if i % saving_interval == 0:\n",
    "            # r, c = 5, 5\n",
    "            noise = np.random.normal(0, 1, (25, 100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            # Rescale images 0 - 1\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "            fig, axs = plt.subplots(5, 5)\n",
    "            \n",
    "            count = 0\n",
    "\n",
    "            for j in range(5):\n",
    "                for k in range(5):\n",
    "                    axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                    axs[j, k].axis('off')\n",
    "                    count += 1\n",
    "\n",
    "            fig.savefig('gan_images/gan_mnist_%d.png' % i)\n",
    "\n",
    "# 2000번 반복되고 +1\n",
    "# 배치 크기는 32, 200번마다 결과 저장\n",
    "gan_train(2001, 32, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72bf2f-f959-4b28-80e0-21bb9354a7f7",
   "metadata": {},
   "source": [
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 201ms/step<br>\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step<br>\n",
    "epoch:1  d_loss:0.6863  g_loss:0.6925<br>\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step<br>\n",
    "epoch:2  d_loss:0.6858  g_loss:0.6869<br>\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step<br>\n",
    "epoch:3  d_loss:0.6852  g_loss:0.6810<br>\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step<br>\n",
    "<br>\n",
    "...<br>\n",
    "<br>\n",
    "epoch:940  d_loss:0.4634  g_loss:0.2399<br>\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 37ms/step<br>\n",
    "epoch:941  d_loss:0.4633  g_loss:0.2398<br>\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step<br>\n",
    "epoch:942  d_loss:0.4633  g_loss:0.2397<br>\n",
    "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step<br>\n",
    "<br>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49fca5-d465-4998-98d6-1ec09c70d146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
